#!/usr/bin/env python
#
# // SPDX-License-Identifier: BSD-3-CLAUSE
#
# (C) Copyright 2018, Xilinx, Inc.
#
import numpy as np
# from . import xdnn
import xdnn
import argparse
import os
import json
import math
import cv2
#import PyTurboJPEG

def default_parser_args():
    parser = argparse.ArgumentParser(description='pyXDNN')
    parser.add_argument('--xdnnv3', type = str, default = 'false',
        help='is xdnnv3')
    parser.add_argument('--platform',
        help='What platform are you running on')
    parser.add_argument('--xclbin',
        help='.xclbin file')
    parser.add_argument('--batch_sz', type=int, default=1,
        help='batch size')  
    parser.add_argument('--netcfg',
        help='FPGA instructions generated by compiler for the network')
    parser.add_argument('--quantizecfg', default="",
        help='FPGA config file')
    parser.add_argument('--xlnxlib',
        help='FPGA xfDNN lib .so')
    parser.add_argument('--fpgaoutsz', type=int, default=1024,
        help='size of 1 FPGA output blob')
    parser.add_argument('--outsz', type=int, default=1000,
        help='size of last layer\'s output blob')   
    parser.add_argument('--firstfpgalayer', default="",
        help='name of first FPGA layer (to start quantization)')
    parser.add_argument('--datadir',
        help='path to data files to run for the network')
    parser.add_argument('--labels', default="",
        help='result -> labels translation file')
    parser.add_argument('--jsoncfg',
        help='json file with nets, data and PEs to use'),
    parser.add_argument('--images', nargs='*',
        help='raw image files to use as input')
    parser.add_argument('--transform', type=str, default='resize',
        help='input image processing transform (i.e. resize, yolo, etc.')
    parser.add_argument('--scaleA', type=int, default=10000,
        help='weights scaling value')
    parser.add_argument('--scaleB', type=int, default=30,
        help='activation scaling value ')
    parser.add_argument('--img_raw_scale', type=float, default=255.0,
        help='image raw scale value ')
    parser.add_argument('--img_mean', type=tuple, default=(104.007, 116.669, 122.679),  # BGR for Caffe 
        help='image mean values ')
    parser.add_argument('--img_input_scale', type=float, default=1.0,
        help='image input scale value ')
    parser.add_argument('--in_shape', type=tuple, default=(3, 224, 224), help='input dimensions') 
    parser.add_argument('--useblas', default=False, action='store_true',
        help='use BLAS-optimized functions (requires xfDNN lib compiled with BLAS)')
    parser.add_argument('--PE', nargs='?', type=int, default=-1,
        help='preferred PE to run the classification on. Default is auto-select')
    parser.add_argument('--blocking', nargs='?',
            help='use blocking calls. Default is blocking')     
    parser.add_argument('--endLayerName', default="",
            help='layer name till the network should be run, helpful for debugging')
    parser.add_argument('--diffStartLayer', type=int, default=0,
            help="if 1 then we can run from any given layer ignoring the X's of first layers")
    parser.add_argument('--v2WeightsFormat', type=int, default=0,
            help="Weights File specified as KernSizex KernSizey instead of only KernSize, supporting rectangle kernels")
    parser.add_argument('--layerName', default="",
            help='layername until which pyfpga should run, if left default, would run the entire model')
    parser.add_argument('--binaryFormatWeights', type=int, default=0,
            help="Binary Format Weights Files")
    return parser

def make_dict_args(args):
    args_dict = vars(args)
    
    if args_dict['images'] is not None and os.path.isdir(args_dict['images'][0]):
        inputFiles = [os.path.join(args_dict['images'][0], f) \
        for f in os.listdir(args_dict['images'][0]) if os.path.isfile(os.path.join(args_dict['images'][0], f))]
        args_dict['images'] = inputFiles
    
    if args_dict['jsoncfg']:
            fileName = args_dict['jsoncfg']
            args_dict['jsoncfg'] = args_dict
            with open(fileName) as jsoncfgFile:
                    args_dict['jsoncfg'] = json.load(jsoncfgFile)['confs']
                    new_args = []
                    for dict_elem in args_dict['jsoncfg']:
                            # if item.key
                            # for key,value in dict_elem.items():
                            for key, value in list(args_dict.items()):
                                    if key not in dict_elem:
                                            dict_elem[key] = value
                                            
                            new_args.append(dict_elem)
                     
                    # print new_args
                    args_dict['jsoncfg'] = new_args
                    for dict_elem in args_dict['jsoncfg']:
                      for key,val in dict_elem.iteritems():
                        try:
                          dict_elem[key] = int(val)
                        except:
                          pass
    return args_dict   
                    
def processCommandLine(argv=None):
    """
    Invoke command line parser for command line deployment flows.
    """
    parser = default_parser_args()
    args = parser.parse_args(argv)
    return make_dict_args(args)     

def loadImageBlobFromFile(imgFile, raw_scale, mean, input_scale, img_h, img_w):
    if isinstance(imgFile,str):
        #img = PyTurboJPEG.imread  ( imgFile)
        img = cv2.imread  ( imgFile)
    
    height, width, _ = img.shape
    if height != img_h or width != img_w:
        img = cv2.resize(img, (img_h, img_w))

    #print "Bryan: ", np.max(img)
    #print "Bryan: ", np.min(img)

    # Not needed for Caffe because BGR:
    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # FIXME TF retrained
    if raw_scale != 255:
        array = img.astype(np.float32) / 255
        array *= raw_scale
    mean_arr = np.array(mean)
    array = img - mean_arr
    if input_scale != 1:
        array *= input_scale

    # prepare blob
    array = np.transpose(array, (2, 0, 1))
    array = np.broadcast_to( array, (1,) + array.shape )
    
    # array = array.flatten() # FIXME TF retrained
    
    return array

    
def loadYoloImageBlobFromFile(imgFile, img_h, img_w):
    # This first loads the image, runs BGR->RGB, converts int 0-255 to floats 0.0-1.0, then letterboxes

    import cv2
    img = cv2.imread(imgFile)

    # YOLO was trained with RGB, not BGR like Caffe:
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    height, width, channels = img.shape
    
    newdim = max(height, width)
    scalew = float(width) / newdim
    scaleh = float(height) / newdim
    neww = int(img_w * scalew)
    newh = int(img_h * scaleh)

    reduced_img = cv2.resize(img, (neww, newh))

    reduced_img_float = reduced_img / 255.0

    newdim = max(newh, neww)
    diffh = newdim - newh
    diffw = newdim - neww
    letter_image_float = np.zeros((newdim, newdim, channels), np.float)
    letter_image_float[:, :, :] = 0.5
    letter_image_float[diffh / 2:newh + diffh / 2, diffw / 2:neww + diffw / 2] = reduced_img_float

    # prepare blob (channel, row, column)
    array = np.transpose(letter_image_float, (2, 0, 1))
    array = np.broadcast_to( array, (1,) + array.shape )
    #array = np.transpose(letter_image_float, (2, 0, 1)).flatten()

    return array, img.shape


def loadImages (files, transform, img_raw_scale, img_mean, img_input_scale, img_shape):
    inputs = np.zeros( ( (len(files),) + img_shape), dtype=np.float32)
    
    shapes = [None] * len(files)
    # use raw image files from user

    for i, fname in enumerate(files):
      if transform == 'resize':
        inputs[i] = loadImageBlobFromFile(fname, img_raw_scale, img_mean, img_input_scale, img_shape[1], img_shape[2])
        shapes[i] = None
      elif transform == 'yolo':
        inputs[i], shapes[i] = loadYoloImageBlobFromFile(fname, img_shape[1], img_shape[2])
      else:
        assert 0, "Unrecognized image transform"
    
    return inputs, shapes


def loadRawDataInput (file, num_images, img_shape):
    import os
    from collections import Iterable
    if not isinstance(img_shape, Iterable):
        img_shape = eval(img_shape)

    inputs = np.zeros((num_images, np.prod(img_shape)), dtype=np.float32)
    shapes = [None] * num_images
    
# use saved image data from framework
    fname = "%s/input" % file 
    if not os.path.isfile(fname):
        raise Exception('Input file not found')
        
    with open(fname, 'r') as f:
        for i in range(num_images):
                line = f.readline()
                if not line:
                    break
        
                vals = line.strip().split(' ')
                vals = [float(v) for v in vals]
        
                inputs[i] = vals
                shapes[i] = img_shape
        return inputs, shapes

def getClassification(output, args):
    if isinstance (output, np.ndarray):
        output = output.flatten().tolist()

    labels = []
    with open(args['labels'], 'r') as f:
        for line in f:
            labels.append(line.strip())

    idxArr   = [i for i in range(args['outsz'])]
    batch_sz = len(output) / args['outsz']
    result   = []
    for i in range(batch_sz):
      startIdx = i * args['outsz']
      vals     = output[startIdx:startIdx + args['outsz']]
      top5     = sorted(zip(vals, idxArr), reverse=True)[:5]
      result  += [[(top5[j][0], labels[top5[j][1]]) for j in range(len(top5))]]

    return result

def printClassification(output, args):
    """
    Print the result of classification given class scores, and a synset labels file.

    :param output: Class scores, typically the output of the softmax layer.
    :type output: numpy.ndarray.
    :param args: Collection of arguments. Most importanly args["labels"] which is the path to a file containing class names.
    :type args: dict.
    """
    top5s = getClassification(output, args)

    print("\n")
    for i, top5 in enumerate(top5s):
      inputImage = ""
      if args['images']:
        inputImage = "for %s " % args['images'][i]

      print("---------- Prediction %d/%d %s----------" % (i, len(top5s)-1, inputImage))

      for (prob, label) in top5:
        print("%.4f - \"%s\"" % (prob, label))
      print("")

def XDLFprepareRawInputs(args, RawInputs, PE=-1):
    fpgaInputs = xdnn.prepareInputsForFpga(RawInputs, args['quantizecfg'], args['scaleB'], PE, args['firstfpgalayer'])
    return fpgaInputs

def prepareOutput(output_sz, batch_sz):
  (fpgaOutput, _) = xdnn.makeFPGAFloatArray(output_sz*batch_sz)

  return fpgaOutput    

def XDLFloadWeights ( args,Weights,outChans,inChans,kernH,kernW,layerName, isxdnnv3=False) :
  print "Loading weights/bias/quant_params to FPGA..."
  
  if isxdnnv3=="True":
    size = xdnn.v3computeWeightsBiasQuantSize(kernW, kernH, outChans, int(math.ceil(float(inChans)/float(96))), 0, 0, False)
    size=size*2
  else:
    size = xdnn.computeWeightsBiasQuantSize(\
          kernW,kernH,inChans,outChans,True if args['quantizecfg'] else False)

  blob = xdnn.makeWeightsBiasQuantBlob(size)
  bias=[0 for v in range(outChans)]
  if isxdnnv3=="True":
    offset = xdnn.v3fillWeightsBiasQuantBlob(blob, 0, 
          args['quantizecfg'], Weights, args['scaleA'], bias, args['scaleB'],
          kernW,kernH,inChans,outChans,layerName)
  else:
    offset = xdnn.fillWeightsBiasQuantBlob(blob, 0, 
          args['quantizecfg'], Weights, args['scaleA'], bias, args['scaleB'],
          kernW,kernH,inChans,outChans,layerName)
  fps = xdnn.loadBlobToDdr(blob, size, int(args['PE']))

  return (blob, fps)

def XDLFBunchComputeSizeLatestRepl(args, outChans, inChans, kernH, kernW,srcFullSectNum, srcReplSectNum, srcReplUnitNum, isxdnnv3=False):
  is8Bit=True
  if isxdnnv3=="True":
    size = xdnn.v3computeWeightsBiasQuantSize(kernW, kernH, outChans, int(srcFullSectNum), int(srcReplSectNum), int(srcReplUnitNum), True)
    size=size*2
  else:
    size = xdnn.computeWeightsBiasQuantSize(\
          kernW,kernH,inChans,outChans,True if args['quantizecfg'] else False)

  return size

def prepareRawInputs(args, PE=-1):
    print('import Raw Input')
    if args['batch_sz'] != 1:
        batch_sz = int(args['batch_sz'])
    else:
        batch_sz = 1
    inputs, shapes = loadRawDataInput (args['datadir'], batch_sz, args['in_shape'])
    #print('image shape {}, path {}, {}'.format(inputs.shape, args['datadir'], inputs[:10]))
    fpgaInputs = xdnn.prepareInputsForFpga(inputs, args['quantizecfg'], args['scaleB'], PE, args['firstfpgalayer'])
        
    return fpgaInputs, shapes, batch_sz


def prepareImages(args, PE=-1):
    batch_sz = len(args['images'])
    inputs, shapes = loadImages(args['images'], args['transform'], args['img_raw_scale'], args['img_mean'], args['img_input_scale'], args['in_shape'])
    #print('image shape {}, path {}, {}'.format(inputs.shape, args['images'], inputs[:10]))
    fpgaInputs = xdnn.prepareInputsForFpga(inputs, args['quantizecfg'], args['scaleB'], PE, args['firstfpgalayer'])

    return fpgaInputs, shapes, batch_sz


def loadWeights (args) :
    """
    Load weights to off chip device memory. The weights are first quantized.

    :param args: Collection of arguments. Most importanly args["datadir"] which is the path to a folder containing weights & biases.
    :type args: dict.
    :returns: tuple -- (weightsBlob, fcWeight, fcBias) -- <class 'xdnn.LP_c_short'>, numpy.ndarray, numpy.ndarray
    """
    if 'xdnnv3' in args and args['xdnnv3'] == 'true':
      weightsBlob = loadWeightsBiasQuantv3(args)
    else:
      weightsBlob = loadWeightsBiasQuant(args)
    (fcWeight, fcBias) = loadFCWeightsBias(args['datadir'])
    return (weightsBlob, fcWeight, fcBias)


def prepareInput (args, PE=-1):
    """
    Allocate memory for inputs, load images from disk, images will be scaled, letteboxed, and preprocessed.

    :param args: Collection of arguments. Most importanly args["images"] which is a list of images to prepare.
    :type args: dict.
    :param PE: Index used to target specific processing element. Use -1 for autoselect. There can be from 1 to 6 processing elements in a particular xclbin.
    :type PE: int.
    :returns: tuple -- (fpgaInputs,batch_sz) -- <class 'xdnn.LP_c_short_Array_1'>, int
    """
    if args['images'] is not None:
        (fpgaInputs, shapes, batch_sz) = prepareImages(args, PE)
    else:
        (fpgaInputs, shapes, batch_sz) = prepareRawInputs(args, PE)
        
    if args['transform'] == 'yolo':
        return fpgaInputs, shapes, batch_sz
    else:
        return fpgaInputs, batch_sz


def prepareOutput(output_sz, batch_sz):
    """
    Allocate memory for outputs.

    :param output_sz: Number of elements in the output volume returned by FPGA for a single inference. This is specific to the network. 
    :type output_sz: int.
    :param batch_sz: Number of images to be processed simultaneously.
    :type batch_sz: int.
    :returns: numpy.ndarray -- 1D Array large enough to hold output_sz*batch_sz elements.
    """
    (fpgaOutput, fpgaHandle) = xdnn.makeFPGAFloatArray(output_sz * batch_sz)

    return fpgaOutput       


def XDLFloadWeights (args, Weights, outChans, inChans, kernH, kernW, layerName, isxdnnv3=False) :
    print("Loading weights/bias/quant_params to FPGA...")
    
    if isxdnnv3 == "True":
        size = xdnn.v3computeWeightsBiasQuantSize(kernW, kernH, outChans, int(math.ceil(float(inChans) / float(96))), 0, 0, False)
        size = size * 2
    else:
        size = xdnn.computeWeightsBiasQuantSize(\
                    kernW, kernH, inChans, outChans, True if args['quantizecfg'] else False)

    blob = xdnn.makeWeightsBiasQuantBlob(size)
    bias = [0 for v in range(outChans)]
    if isxdnnv3 == "True":
        offset = xdnn.v3fillWeightsBiasQuantBlob(blob, 0,
                    args['quantizecfg'], Weights, args['scaleA'], bias, args['scaleB'],
                    kernW, kernH, inChans, outChans, layerName)
    else:
        offset = xdnn.fillWeightsBiasQuantBlob(blob, 0,
                    args['quantizecfg'], Weights, args['scaleA'], bias, args['scaleB'],
                    kernW, kernH, inChans, outChans, layerName)
    layer2OffsetMap = "%s:%d" % (layerName, 0)
    fps = xdnn.loadBlobToDdr(blob, size, layer2OffsetMap, int(args['PE']))

    return (blob, fps)


def XDLFBunchComputeSizeLatestRepl(args, outChans, inChans, kernH, kernW, srcFullSectNum, srcReplSectNum, srcReplUnitNum, isxdnnv3=False):

    if isxdnnv3 == "True":
        size = xdnn.v3computeWeightsBiasQuantSize(kernW, kernH, outChans, int(srcFullSectNum), int(srcReplSectNum), int(srcReplUnitNum), False)
        size = size * 2
    else:
        size = xdnn.computeWeightsBiasQuantSize(\
                    kernW, kernH, inChans, outChans, True if args['quantizecfg'] else False)

    return size


def XDLFBunchloadWeightsBiasQuantLatestRepl(args, allLayerNames, allLayersWeightsBiasQuantizeKey, allConvLayerNamesParams, size, isxdnnv3):
    print("Loading weights/bias/quant_params to FPGA...")
    
    blob = xdnn.makeWeightsBiasQuantBlob(size)

    offset = 0
    
    layer2OffsetMapStr = ""
    for layerName in allLayerNames:
        if layer2OffsetMapStr != "":
            layer2OffsetMapStr += ","
        layer2OffsetMapStr += "%s:%d" % (layerName, offset)

        if isxdnnv3 == "True":
            offset += xdnn.v3fillWeightsBiasQuantBlob(blob, offset,
                    args['quantizecfg'], allLayersWeightsBiasQuantizeKey[layerName]['weights'], args['scaleA'], allLayersWeightsBiasQuantizeKey[layerName]['Bias'], args['scaleB'],
                 allLayersWeightsBiasQuantizeKey[layerName]['kernW'], allLayersWeightsBiasQuantizeKey[layerName]['kernH'], allLayersWeightsBiasQuantizeKey[layerName]['inChans'], allLayersWeightsBiasQuantizeKey[layerName]['outChans'], int(allConvLayerNamesParams[layerName]['srcFullSectNum']), int(allConvLayerNamesParams[layerName]['srcReplSectNum']), int(allConvLayerNamesParams[layerName]['srcReplUnitNum']), int(allConvLayerNamesParams[layerName]['srcReplUnitWidth']), int(allConvLayerNamesParams[layerName]['convHalfRateMode']), layerName)
        else:
            offset += xdnn.fillWeightsBiasQuantBlob(blob, offset,
                    args['quantizecfg'], allLayersWeightsBiasQuantizeKey[layerName]['weights'], args['scaleA'], allLayersWeightsBiasQuantizeKey[layerName]['Bias'], args['scaleB'],
                 allLayersWeightsBiasQuantizeKey[layerName]['kernW'], allLayersWeightsBiasQuantizeKey[layerName]['kernH'], allLayersWeightsBiasQuantizeKey[layerName]['inChans'], allLayersWeightsBiasQuantizeKey[layerName]['outChans'], layerName)
    fps = xdnn.loadBlobToDdr(blob, size, layer2OffsetMapStr, int(args['PE']))

    return (blob, fps)


def XDLFBunchComputeSize(args, outChans, inChans, kernH, kernW, isxdnnv3=False):

    if isxdnnv3 == "True":
        size = xdnn.v3computeWeightsBiasQuantSize(kernW, kernH, outChans, int(math.ceil(float(inChans) / float(96))), 0, 0, False)
        size = size * 2
    else:
        size = xdnn.computeWeightsBiasQuantSize(\
                    kernW, kernH, inChans, outChans, True if args['quantizecfg'] else False)

    return size


def XDLFBunchloadWeightsBiasQuant(args, allLayerNames, allLayersWeightsBiasQuantizeKey, size, isxdnnv3):
    print("Loading weights/bias/quant_params to FPGA...")
    
    print("MNDBG total A size %d" % size)
    blob = xdnn.makeWeightsBiasQuantBlob(size)

    layer2OffsetMapStr = ""
    offset = 0

    for layerName in allLayerNames:
        if layer2OffsetMapStr != "":
            layer2OffsetMapStr += ","
        layer2OffsetMapStr += "%s:%d" % (layerName, offset)

        if isxdnnv3 == "True":
            offset += xdnn.v3fillWeightsBiasQuantBlob(blob, offset,
                    args['quantizecfg'], allLayersWeightsBiasQuantizeKey[layerName]['weights'], args['scaleA'], allLayersWeightsBiasQuantizeKey[layerName]['Bias'], args['scaleB'],
                 allLayersWeightsBiasQuantizeKey[layerName]['kernW'], allLayersWeightsBiasQuantizeKey[layerName]['kernH'], allLayersWeightsBiasQuantizeKey[layerName]['inChans'], allLayersWeightsBiasQuantizeKey[layerName]['outChans'], layerName)
        else:
            offset += xdnn.fillWeightsBiasQuantBlob(blob, offset,
                    args['quantizecfg'], allLayersWeightsBiasQuantizeKey[layerName]['weights'], args['scaleA'], allLayersWeightsBiasQuantizeKey[layerName]['Bias'], args['scaleB'],
                 allLayersWeightsBiasQuantizeKey[layerName]['kernW'], allLayersWeightsBiasQuantizeKey[layerName]['kernH'], allLayersWeightsBiasQuantizeKey[layerName]['inChans'], allLayersWeightsBiasQuantizeKey[layerName]['outChans'], layerName)
    fps = xdnn.loadBlobToDdr(blob, size, layer2OffsetMapStr, int(args['PE']))

    return (blob, fps)

def parseCompilerFile(compilerFileName):
  with open(compilerFileName) as compilerReadStream:
    compilerContent = compilerReadStream.readlines()
  compilerContent = [x.strip().split(" ") for x in compilerContent]
  allLayersParams={}
  layerParams={}
  allLayerNames=[]
  for i in range(len(compilerContent)):
    if compilerContent[i][1] == "XNConv":
      layerParams={}
      if compilerContent[i][2] not in allLayerNames:
        allLayerNames.append(compilerContent[i][2])
      layerParams['kernW']=compilerContent[i][3]
      layerParams['kernH']=compilerContent[i][4]
      layerParams['inChans']=compilerContent[i][19]
      layerParams['outChans']=compilerContent[i][23]
      layerParams['srcFullSectNum']=compilerContent[i][25]
      layerParams['srcReplSectNum']=compilerContent[i][26]
      layerParams['srcReplUnitNum']=compilerContent[i][27]
      layerParams['srcReplUnitWidth']=compilerContent[i][28]
      layerParams['convHalfRateMode']=compilerContent[i][47]

      allLayersParams[compilerContent[i][2]]=layerParams
    elif compilerContent[i][1] == "XNMaxPoolPipelined":
      layerParams={}
      if compilerContent[i][47] not in allLayerNames:
        allLayerNames.append(compilerContent[i][47])
      layerParams['kernW']=compilerContent[i][48]
      layerParams['kernH']=compilerContent[i][49]
      layerParams['inChans']=compilerContent[i][12]
      layerParams['outChans']=compilerContent[i][60]
      layerParams['srcFullSectNum']=compilerContent[i][17]
      layerParams['srcReplSectNum']=compilerContent[i][18]
      layerParams['srcReplUnitNum']=compilerContent[i][19]
      layerParams['srcReplUnitWidth']=compilerContent[i][20]
      layerParams['convHalfRateMode']=compilerContent[i][39]

      allLayersParams[compilerContent[i][47]]=layerParams

  return allLayerNames, allLayersParams


def loadWeightsBiasQuantv3(args):
    print("Loading weights/bias/quant_params to FPGA...")
    allConvLayerNames, allConvLayerNamesParams = parseCompilerFile(args['netcfg'])
    
    size = 0
    fi = 0
    while True:
        fname = "%s/fwbqb_%d" % (args['datadir'], fi)
        if not os.path.isfile(fname):
            break
        
        layerName = None
        weights = None
        bias = None
        kern = None
        inChans = None
        outChans = None

        with open(fname, 'r') as f:
            data = f.read()
            vals = data.strip().split(' ')
            layerName = vals[0]
            kern = int(vals[1])
            assert kern == int(allConvLayerNamesParams[layerName]['kernW'])
            assert kern == int(allConvLayerNamesParams[layerName]['kernH'])
            inChans = int(vals[2])
            assert inChans == int(allConvLayerNamesParams[layerName]['inChans'])
            outChans = int(vals[3])
    #        assert outChans == int(allConvLayerNamesParams[layerName]['outChans'])

            srcFullSectNum = int(allConvLayerNamesParams[layerName]['srcFullSectNum'])
            srcReplSectNum = int(allConvLayerNamesParams[layerName]['srcReplSectNum'])
            srcReplUnitNum = int(allConvLayerNamesParams[layerName]['srcReplUnitNum'])
        size += xdnn.v3computeWeightsBiasQuantSize(kern, kern, outChans, srcFullSectNum, srcReplSectNum, srcReplUnitNum, False)

        fi += 1

    size = size*2
    blob = xdnn.makeWeightsBiasQuantBlob(size)


    fi = 0
    offset = 0
    layer2OffsetMapStr = ""
    while True:
        fname = "%s/fwbqb_%d" % (args['datadir'], fi)
        if not os.path.isfile(fname):
            break
        
        layerName = None
        weights = None
        bias = None
        kern = None
        inChans = None
        outChans = None

        with open(fname, 'r') as f:
            data = f.read()
            vals = data.strip().split(' ')
            layerName = vals[0]
            kern = int(vals[1])
            assert kern == int(allConvLayerNamesParams[layerName]['kernW'])
            assert kern == int(allConvLayerNamesParams[layerName]['kernH'])
            inChans = int(vals[2])
            assert inChans == int(allConvLayerNamesParams[layerName]['inChans'])
            outChans = int(vals[3])
     #       assert outChans == int(allConvLayerNamesParams[layerName]['outChans'])

            srcFullSectNum = int(allConvLayerNamesParams[layerName]['srcFullSectNum'])
            srcReplSectNum = int(allConvLayerNamesParams[layerName]['srcReplSectNum'])
            srcReplUnitNum = int(allConvLayerNamesParams[layerName]['srcReplUnitNum'])
            srcReplUnitWidth = int(allConvLayerNamesParams[layerName]['srcReplUnitWidth'])
            convHalfRateMode = int(allConvLayerNamesParams[layerName]['convHalfRateMode'])

            vals = vals[4:]
            weights = [float(v) for v in vals]

        fname = "%s/fwbqb_bias_%d" % (args['datadir'], fi)
        with open(fname, 'r') as f:
            data = f.read()
            vals = data.strip().split(' ')
            vals = vals[4:]
            bias = [float(v) for v in vals]

        if layer2OffsetMapStr != "":
            layer2OffsetMapStr += ","
        layer2OffsetMapStr += "%s:%d" % (layerName, offset)

        offset += xdnn.v3fillWeightsBiasQuantBlob(blob, offset,
                args['quantizecfg'], weights, args['scaleA'], bias, args['scaleB'],
                kern, kern, inChans, outChans, srcFullSectNum, srcReplSectNum, srcReplUnitNum, srcReplUnitWidth, convHalfRateMode, layerName)

        fi += 1
    xdnn.loadBlobToDdr(blob, size, layer2OffsetMapStr, int(args['PE']))

    return blob


def loadWeightsBiasQuant(args):
    print("Loading weights/bias/quant_params to FPGA...")
    
    size = 0
    fi = 0
    while True:
        fname = "%s/wbq_size_%d" % (args['datadir'], fi)
        if not os.path.isfile(fname):
            break
        
        with open(fname, 'r') as f:
            data = f.read()
            vals = data.strip().split(' ')
            vals = [int(v) for v in vals]
            if 'v2WeightsFormat' in args and args['v2WeightsFormat'] == 1:
                size += xdnn.computeWeightsBiasQuantSize(\
                    vals[0], vals[1], vals[2], vals[3], True if args['quantizecfg'] else False)
            else:
                size += xdnn.computeWeightsBiasQuantSize(\
                    vals[0], vals[0], vals[1], vals[2], True if args['quantizecfg'] else False)

        fi += 1

    # print "ANDBG total A size %d" % size
    blob = xdnn.makeWeightsBiasQuantBlob(size)

    fi = 0
    offset = 0
    layer2OffsetMapStr = ""
    while True:
        fname = "%s/fwbqb_%d" % (args['datadir'], fi)
        if 'binaryFormatWeights' in args:
            if args['binaryFormatWeights'] == 1:
                fname = "%s/fwbqbbinary_%d.bin" % (args['datadir'], fi)
        if not os.path.isfile(fname):
            break
        
        layerName = None
        weights = None
        bias = None
        if 'v2WeightsFormat' in args and args['v2WeightsFormat'] == 1:
            kernWidth = None
            kernHeight = None
        else:
            kern = None
        inChans = None
        outChans = None

        if 'binaryFormatWeights' in args:
            if args['binaryFormatWeights'] == 1:
                if 'v2WeightsFormat' in args and args['v2WeightsFormat'] != 1:
                    print("Weights should be given in the v2WeightsFormat, KernSizex and KernSizey. If they are already\
                        in v2WeightsFormat, then set the argument v2WeightsFormat to 1")
                    sys.exit(1)
                vals = []
                (layerName, kernWidth, kernHeight, inChans, outChans, vals) = xdnn.readWeightsFile(fname)
                weights = [float(v) for v in vals]
            elif args['binaryFormatWeights'] == 0:
                with open(fname, 'r') as f:
                    data = f.read()
                    vals = data.strip().split(' ')
                    layerName = vals[0]
                    if 'v2WeightsFormat' in args and args['v2WeightsFormat'] == 1:
                        kernWidth = int(vals[1])
                        kernHeight = int(vals[2])
                        inChans = int(vals[3])
                        outChans = int(vals[4])
                        vals = vals[5:]
                    else:
                        kern = int(vals[1])
                        inChans = int(vals[2])
                        outChans = int(vals[3])
                        vals = vals[4:]
                    weights = [float(v) for v in vals]
        else:
            with open(fname, 'r') as f:
                data = f.read()
                vals = data.strip().split(' ')
                layerName = vals[0]
                if 'v2WeightsFormat' in args and args['v2WeightsFormat'] == 1:
                    kernWidth = int(vals[1])
                    kernHeight = int(vals[2])
                    inChans = int(vals[3])
                    outChans = int(vals[4])
                    vals = vals[5:]
                else:
                    kern = int(vals[1])
                    inChans = int(vals[2])
                    outChans = int(vals[3])
                    vals = vals[4:]
                weights = [float(v) for v in vals]

        fname = "%s/fwbqb_bias_%d" % (args['datadir'], fi)
        with open(fname, 'r') as f:
            data = f.read()
            vals = data.strip().split(' ')
            if 'v2WeightsFormat' in args:
                if args['v2WeightsFormat'] == 1:
                    vals = vals[5:]
                elif args['v2WeightsFormat'] == 0:
                    vals = vals[4:]
            else:
                vals = vals[4:]
            bias = [float(v) for v in vals]

        if layer2OffsetMapStr != "":
            layer2OffsetMapStr += ","
        layer2OffsetMapStr += "%s:%d" % (layerName, offset)

        # print "ANDBG %d %s %d %d %d" % (offset, layerName, fi, len(weights), len(bias))
        if 'v2WeightsFormat' in args and args['v2WeightsFormat'] == 1:
            offset += xdnn.fillWeightsBiasQuantBlob(blob, offset,
                args['quantizecfg'], weights, args['scaleA'], bias, args['scaleB'],
                kernWidth, kernHeight, inChans, outChans, layerName)
        else:
            offset += xdnn.fillWeightsBiasQuantBlob(blob, offset,
                args['quantizecfg'], weights, args['scaleA'], bias, args['scaleB'],
                kern, kern, inChans, outChans, layerName)

        fi += 1
    xdnn.loadBlobToDdr(blob, size, layer2OffsetMapStr, int(args['PE']))

    return blob


def getNearFileMatchWithPrefix(path, prefix):
    nearMatches = [f for f in os.listdir(path) if f.startswith(prefix)]
    nearMatches.sort()
    if len(nearMatches) > 0:
        return "%s/%s" % (path, nearMatches[0])

    return None


def loadFCWeightsBias(data_dir):
    weight = []
    fname = "%s/fc" % data_dir
    if not os.path.exists(fname):
        nearMatch = getNearFileMatchWithPrefix(data_dir, "fc")
        if nearMatch:
            fname = nearMatch
    if os.path.exists(fname):
        with open(fname, 'r') as f:
            line = f.read()
            vals = line.strip().split(' ')
            weight = [float(v) for v in vals]
    else:
        print(("No FC layers found in %s" % data_dir))
        return (None, None)

    bias = []
    fname = "%s/fc_bias" % data_dir
    if not os.path.exists(fname):
        nearMatch = getNearFileMatchWithPrefix(data_dir, "fc_bias")
        if nearMatch:
            fname = nearMatch
    with open(fname, 'r') as f:
        line = f.read()
        vals = line.strip().split(' ')
        bias = [float(v) for v in vals]

    (weightFpga, fpgaHandle) = xdnn.makeFPGAFloatArray(len(weight))
    (biasFpga, fpgaHandle) = xdnn.makeFPGAFloatArray(len(bias))

    weightFpga[:] = weight
    biasFpga[:] = bias

    return (weightFpga, biasFpga)
    
# def default_rt_args():
        # parser = argparse.ArgumentParser()

        
def default_compiler_args():
        parser = argparse.ArgumentParser()
        parser.add_argument("--memory", type=int, default=8)
        parser.add_argument("--generatefile", type=str)
        parser.add_argument("--dsp", type=int, default=28)
        parser.add_argument("--ddr", type=int, default=4096)
        parser.add_argument("--versionjson", type=str, default=None)
        parser.add_argument("--fromtensorflow", default=True)
        parser.add_argument("--weights", default=False)
        parser.add_argument("--strategy", type=str, default="all")
        parser.add_argument("--schedulefile", type=str)
        parser.add_argument("--pngfile", type=str)
        parser.add_argument("--rankdir", type=str, default='BT')
        parser.add_argument("--bytesperpixels", type=int, default=1)
        parser.add_argument("--finalnode", type=str, default=None)
        parser.add_argument("--networkfile", type=str, required=True)
        parser.add_argument("--placeholdershape", type=str, default=None)
        parser.add_argument("--verbose", type=bool, default=False)
        parser.add_argument("--lasttensorbyname", type=str, default=None)
        parser.add_argument("--concatstrategy", type=str, default=None)
        parser.add_argument("--dedicateddsp", type=bool, default=False)
        
        parser.add_argument("--device", type=str, required=True, choices=['CPU', 'FPGA', 'HWEmu'])      
        return parser

